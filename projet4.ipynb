{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11dfa9a4",
   "metadata": {},
   "source": [
    "Import packages, load CSV files, and create copies of the datasets to clean them without corrupting the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01fa0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read csv\n",
    "books_clean = pd.read_csv('books.csv')\n",
    "ratings_clean = pd.read_csv('ratings.csv')\n",
    "book_tags_clean = pd.read_csv('book_tags.csv')\n",
    "tags_clean = pd.read_csv('tags.csv')\n",
    "to_read_clean = pd.read_csv('to_read.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f799c0",
   "metadata": {},
   "source": [
    "Data Cleaning (Generic Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a080b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Affichage types données books.csv\")\n",
    "# print(books_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données ratings.csv\")\n",
    "# print(ratings_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données book_tags_clean.csv\")\n",
    "# print(book_tags_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données tags_clean.csv\")\n",
    "# print(tags_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données to_read_clean.csv\")\n",
    "# print(to_read_clean.dtypes)\n",
    "\n",
    "\n",
    "# colonne_errone = []\n",
    "\n",
    "# for colonne in ratings_clean.columns:\n",
    "    # types = ratings_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone ratings :\", colonne_errone)\n",
    "\n",
    "# for colonne in book_tags_clean.columns:\n",
    "    # types = book_tags_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone book_tags :\", colonne_errone)\n",
    "\n",
    "# for colonne in tags_clean.columns:\n",
    "    # types = tags_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone tags :\", colonne_errone)\n",
    "\n",
    "# for colonne in to_read_clean.columns:\n",
    "    # types = to_read_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone to_read :\", colonne_errone)\n",
    "\n",
    "# for colonne in books_clean.columns:\n",
    "    # types = books_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)        \n",
    "# print(\"Colonnes avec types errone books :\", colonne_errone)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Vérification doublons\")\n",
    "# print(f\"Doublons books_clean.csv : {books_clean.duplicated().sum()}\")\n",
    "# print(f\"Doublons ratings_clean.csv : {ratings_clean.duplicated().sum()}\")\n",
    "# print(f\"Doublons book_tags_clean.csv : {book_tags_clean.duplicated().sum()}\")\n",
    "# print(f\"Doublons tags_clean.csv : {tags_clean.csv.duplicated().sum()}\")\n",
    "# print(f\"Doublons to_read_clean.csv : {to_read_clean.csv.duplicated().sum()}\")\n",
    "\n",
    "# Delete duplicates\n",
    "books_clean = books_clean.drop_duplicates()\n",
    "ratings_clean = ratings_clean.drop_duplicates()\n",
    "book_tags_clean = book_tags_clean.drop_duplicates()\n",
    "tags_clean = tags_clean.drop_duplicates()\n",
    "to_read_clean = to_read_clean.drop_duplicates()\n",
    "\n",
    "# Delete spaces\n",
    "books_clean.columns = books_clean.columns.str.strip().str.lower()\n",
    "ratings_clean.columns = ratings_clean.columns.str.strip().str.lower()\n",
    "book_tags_clean.columns = book_tags_clean.columns.str.strip().str.lower()\n",
    "tags_clean.columns = tags_clean.columns.str.strip().str.lower()\n",
    "to_read_clean.columns = to_read_clean.columns.str.strip().str.lower()\n",
    "\n",
    "\n",
    "# print(\"Valeurs manquantes books_clean.csv\")\n",
    "# print(books_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes ratings_clean.csv\")\n",
    "# print(ratings_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes book_tags\")\n",
    "# print(book_tags_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes tags_clean.csv\")\n",
    "# print(tags_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes to_read_clean.csv\")\n",
    "# print(to_read_clean.isnull().sum())\n",
    "\n",
    "\n",
    "# Delete missing values\n",
    "books_clean = books_clean.dropna()\n",
    "ratings_clean = ratings_clean.dropna()\n",
    "book_tags_clean = book_tags_clean.dropna()\n",
    "tags_clean = tags_clean.dropna()\n",
    "to_read_clean = to_read_clean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04751231",
   "metadata": {},
   "source": [
    "Data Cleaning (Specific Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae531d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning tags\n",
    "\n",
    "# Values are over 0 for tag_id\n",
    "tags_clean = tags_clean[tags_clean['tag_id'] > 0]\n",
    "\n",
    "# Replace every \"-\" by \" \"\n",
    "tags_clean['tag_name'] = tags_clean['tag_name'].str.replace(r'^-+', '', regex=True)\n",
    "tags_clean['tag_name'] = tags_clean['tag_name'].str.replace(r'-+$', '', regex=True)\n",
    "tags_clean['tag_name'] = tags_clean['tag_name'].str.replace(r'-+', ' ', regex=True)\n",
    "tags_clean['tag_name'] = tags_clean['tag_name'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcae73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning book_tag\n",
    "\n",
    "# Delete tag_id without match\n",
    "\n",
    "# no_tags_id = book_tags_clean[~book_tags_clean['tag_id'].isin(tags_clean['tag_id'])]\n",
    "# print(\"Valeurs sans correspondance tags_clean : \")\n",
    "# print(no_tags_id['tag_id'].unique())\n",
    "book_tags_clean = book_tags_clean[book_tags_clean['tag_id'].isin(tags_clean['tag_id'])]\n",
    "\n",
    "# Delete book_id without match\n",
    "\n",
    "# no_book_id = book_tags_clean[~book_tags_clean['book_id'].isin(books_clean['book_id'])]\n",
    "# print(\"Valeurs sans correspondance books_clean : \")\n",
    "# print(no_book_id['book_id'].unique())\n",
    "book_tags_clean = book_tags_clean[book_tags_clean['goodreads_book_id'].isin(books_clean['book_id'])]\n",
    "\n",
    "# Values are over 0 for tag_id, count and goodreads_book_id\n",
    "book_tags_clean = book_tags_clean[(book_tags_clean['tag_id'] > 0) & (book_tags_clean['count'] > 0) & (book_tags_clean['goodreads_book_id'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d025bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning ratings\n",
    "\n",
    "# Delete books_id without match\n",
    "\n",
    "# no_id_books = ratings_clean[~ratings_clean['book_id'].isin(books_clean['book_id'])]\n",
    "# print(\"Valeurs sans correspondance books_clean : \")\n",
    "# print(no_id_books['book_id'].unique())\n",
    "ratings_clean = ratings_clean[ratings_clean['book_id'].isin(books_clean['book_id'])]\n",
    "\n",
    "# Values are between 1 and 5 for rating\n",
    "ratings_clean = ratings_clean[(ratings_clean['rating'] > 0) & (ratings_clean['rating'] < 6)]\n",
    "\n",
    "# Values over 0 for book_id and user_id\n",
    "ratings_clean = ratings_clean[(ratings_clean['book_id'] > 0) & (ratings_clean['user_id'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11995245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning to_read\n",
    "\n",
    "# Delete books_id without match\n",
    "\n",
    "# no_books_id = to_read_clean[~to_read_clean['book_id'].isin(books_clean['book_id'])]\n",
    "# print(\"Valeurs sans correspondance books_clean : \")\n",
    "# print(no_books_id['book_id'].unique())\n",
    "to_read_clean = to_read_clean[to_read_clean['book_id'].isin(books_clean['book_id'])]\n",
    "\n",
    "# Values over 0 for book_id and user_id\n",
    "to_read_clean = to_read_clean[(to_read_clean['book_id'] > 0) & (to_read_clean['user_id'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f96b83",
   "metadata": {},
   "source": [
    "Create new files with every changement inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60fd7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean csv\n",
    "books_clean.to_csv('books_clean.csv', index=False)\n",
    "ratings_clean.to_csv('ratings_clean.csv', index=False)\n",
    "book_tags_clean.to_csv('book_tags_clean.csv', index=False)\n",
    "tags_clean.to_csv('tags_clean.csv', index=False)\n",
    "to_read_clean.to_csv('to_read_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
