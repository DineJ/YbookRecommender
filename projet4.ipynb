{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11dfa9a4",
   "metadata": {},
   "source": [
    "Import packages, load CSV files, and create copies of the datasets to clean them without corrupting the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fa0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read csv\n",
    "books_clean = pd.read_csv('books.csv')\n",
    "ratings_clean = pd.read_csv('ratings.csv')\n",
    "book_tags_clean = pd.read_csv('book_tags.csv')\n",
    "tags_clean = pd.read_csv('tags.csv')\n",
    "to_read_clean = pd.read_csv('to_read.csv')\n",
    "\n",
    "# Create clean csv\n",
    "books_clean.to_csv('books_clean.csv', index=False)\n",
    "ratings_clean.to_csv('ratings_clean.csv', index=False)\n",
    "book_tags_clean.to_csv('book_tags_clean.csv', index=False)\n",
    "tags_clean.to_csv('tags_clean.csv', index=False)\n",
    "to_read_clean.to_csv('to_read_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f799c0",
   "metadata": {},
   "source": [
    "Data Cleaning (Generic Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a080b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec types mixtes ratings : []\n",
      "Colonnes avec types mixtes book_tags : []\n",
      "Colonnes avec types mixtes tags : []\n",
      "Colonnes avec types mixtes to_read : []\n",
      "Colonnes avec types mixtes books : []\n"
     ]
    }
   ],
   "source": [
    "# print(\"Affichage types données books.csv\")\n",
    "# print(books_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données ratings.csv\")\n",
    "# print(ratings_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données book_tags_clean.csv\")\n",
    "# print(book_tags_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données tags_clean.csv\")\n",
    "# print(tags_clean.dtypes)\n",
    "\n",
    "# print(\"Affichage type données to_read_clean.csv\")\n",
    "# print(to_read_clean.dtypes)\n",
    "\n",
    "\n",
    "# colonne_errone = []\n",
    "\n",
    "# for colonne in ratings_clean.columns:\n",
    "    # types = ratings_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone ratings :\", colonne_errone)\n",
    "\n",
    "# for colonne in book_tags_clean.columns:\n",
    "    # types = book_tags_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone book_tags :\", colonne_errone)\n",
    "\n",
    "# for colonne in tags_clean.columns:\n",
    "    # types = tags_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone tags :\", colonne_errone)\n",
    "\n",
    "# for colonne in to_read_clean.columns:\n",
    "    # types = to_read_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)\n",
    "# print(\"Colonnes avec types errone to_read :\", colonne_errone)\n",
    "\n",
    "# for colonne in books_clean.columns:\n",
    "    # types = books_clean[colonne].apply(type).nunique()\n",
    "    # if types > 1:\n",
    "        # colonne_errone.append(colonne)        \n",
    "# print(\"Colonnes avec types errone books :\", colonne_errone)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Vérification doublons\")\n",
    "# print(f\"Doublons books_clean.csv : {books_clean.duplicated().sum()}\")\n",
    "# print(f\"Doublons ratings_clean.csv : {ratings_clean.duplicated().sum()}\")\n",
    "# print(f\"Doublons book_tags_clean.csv : {book_tags_clean.duplicated().sum()}\")\n",
    "# print(f\"Doublons tags_clean.csv : {tags_clean.csv.duplicated().sum()}\")\n",
    "# print(f\"Doublons to_read_clean.csv : {to_read_clean.csv.duplicated().sum()}\")\n",
    "\n",
    "\n",
    "# Delete duplicates\n",
    "books_clean = books_clean.drop_duplicates()\n",
    "ratings_clean = ratings_clean.drop_duplicates()\n",
    "book_tags_clean = book_tags_clean.drop_duplicates()\n",
    "tags_clean = tags_clean.drop_duplicates()\n",
    "to_read_clean = to_read_clean.drop_duplicates()\n",
    "\n",
    "# Delete spaces\n",
    "books_clean.columns = books_clean.columns.str.strip().str.lower()\n",
    "ratings_clean.columns = ratings_clean.columns.str.strip().str.lower()\n",
    "book_tags_clean.columns = book_tags_clean.columns.str.strip().str.lower()\n",
    "tags_clean.columns = tags_clean.columns.str.strip().str.lower()\n",
    "to_read_clean.columns = to_read_clean.columns.str.strip().str.lower()\n",
    "\n",
    "\n",
    "# print(\"Valeurs manquantes books_clean.csv\")\n",
    "# print(books_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes ratings_clean.csv\")\n",
    "# print(ratings_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes book_tags\")\n",
    "# print(book_tags_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes tags_clean.csv\")\n",
    "# print(tags_clean.isnull().sum())\n",
    "\n",
    "# print(\"Valeurs manquantes to_read_clean.csv\")\n",
    "# print(to_read_clean.isnull().sum())\n",
    "\n",
    "\n",
    "# Delete missing values\n",
    "books_clean = books_clean.dropna()\n",
    "ratings_clean = ratings_clean.dropna()\n",
    "book_tags_clean = book_tags_clean.dropna()\n",
    "tags_clean = tags_clean.dropna()\n",
    "to_read_clean = to_read_clean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04751231",
   "metadata": {},
   "source": [
    "Data Cleaning (Specific Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11995245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete books_id without match\n",
    "\n",
    "# no_id_books = to_read_clean[~to_read_clean['book_id'].isin(books_clean['book_id'])]\n",
    "# print(\"Valeurs sans correspondance books_clean : \")\n",
    "# print(no_id_books['book_id'].unique())\n",
    "to_read_clean = to_read_clean[to_read_clean['book_id'].isin(books_clean['book_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e5c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete books_id without match\n",
    "\n",
    "# no_id_books = ratings_clean[~ratings_clean['book_id'].isin(books_clean['book_id'])]\n",
    "# print(\"Valeurs sans correspondance books_clean : \")\n",
    "# print(no_id_books['book_id'].unique())\n",
    "ratings_clean = ratings_clean[ratings_clean['book_id'].isin(books_clean['book_id'])]\n",
    "\n",
    "# Values are between 1 and 5\n",
    "ratings_clean = ratings_clean[(ratings_clean['rating'] > 0) & (ratings_clean['rating'] < 6)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63222807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete \n",
    "tags_clean = tags_clean[tags_clean['tag_name'].str.strip() != '']\n",
    "tags_clean['tag_name'] = tags_clean['tag_name'].str.strip().str.lower()\n",
    "tags_clean = tags_clean[~tags_clean['tag_name'].str.contains(r'\\d')]\n",
    "tags_clean = tags_clean[tags_clean['tag_name'].str.len() > 1]\n",
    "tags_clean = tags_clean[~tags_clean['tag_name'].str.contains(r'[^a-z0-9_\\-\\s]', regex=True)]\n",
    "tags_clean = tags_clean.drop_duplicates(subset=['tag_id', 'tag_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26104d92",
   "metadata": {},
   "source": [
    "Formated datasets, created new ones without duplicates and missings datas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
